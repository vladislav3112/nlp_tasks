{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.99)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.34.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.16.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.26.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: nltk in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.17.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.12.0)\n",
      "Requirement already satisfied: requests in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\laptop_user\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.0)\n",
      "Requirement already satisfied: click in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision->sentence-transformers) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\laptop_user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "mask_filler = pipeline(\"fill-mask\", 'distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "SEED = 0\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Здесь описываются параметры и задается входное предложение:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENT_NUM = 10\n",
    "TEMPERATURE = 0.05\n",
    "TOP_K = 5\n",
    "#input_sent = \"After your workout, remember to focus on maintaining a good water balance.\"\n",
    "input_sent = \"The latest tech news about the world's best (and sometimes worst) hardware, apps, and much more.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of using gpt2 to replace ending of sentence at the end\n",
    "USE_GPT2_PROBA = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation', model='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "embedding_input = model.encode(input_sent, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9342713952064514\n",
      "0.7986621856689453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8621166348457336\n",
      "0.717326819896698\n",
      "0.6796664595603943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6527443528175354\n",
      "0.7529996633529663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7963331341743469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8939462304115295\n",
      "0.8368752598762512\n"
     ]
    }
   ],
   "source": [
    "WORDS_TO_REPLACE = len(wordpunct_tokenize(input_sent))//3\n",
    "\n",
    "CROP_WORDS = min(len(wordpunct_tokenize(input_sent))//2, 5)\n",
    "input_sent = input_sent.lower()\n",
    "curr_res = input_sent\n",
    "detokenizer = TreebankWordDetokenizer()\n",
    "predicted_sentences = []\n",
    "while len(predicted_sentences) < SENT_NUM:\n",
    "    for _ in range(WORDS_TO_REPLACE):\n",
    "        words = wordpunct_tokenize(curr_res)\n",
    "        word_to_replace = np.random.randint(len(words))\n",
    "        words[word_to_replace] = tokenizer.mask_token\n",
    "        sequence = detokenizer.detokenize(words)\n",
    "        prediction = mask_filler(sequence, top_k=1)[0]\n",
    "        curr_res = prediction['sequence']\n",
    "        if prediction == words[word_to_replace-1]:\n",
    "            del words[word_to_replace]\n",
    "            curr_res = detokenizer.detokenize(words)\n",
    "    \n",
    "        # with probability TEMPERATURE or while sentence not chnges take predict from [1 TOP_K) pos\n",
    "        if np.random.rand() < TEMPERATURE:\n",
    "            curr_res = mask_filler(sequence, top_k=TOP_K)[np.random.randint(1,TOP_K)]['sequence']\n",
    "        while curr_res == input_sent:\n",
    "            curr_res = mask_filler(sequence, top_k=TOP_K)[np.random.randint(1,TOP_K)]['sequence']\n",
    "    if np.random.rand() < USE_GPT2_PROBA and len(words) > 5:\n",
    "        # crop some part of sentence and continue it with gpt2:\n",
    "        words = wordpunct_tokenize(curr_res)\n",
    "        tmp_res = generator(detokenizer.detokenize(words[:-CROP_WORDS]), max_length=len(words) + CROP_WORDS*2, num_return_sequences=1)[0]['generated_text']\n",
    "        tmp_res = tmp_res[:tmp_res.rfind('.') + 1] # crop by '.' from right end\n",
    "        if len(tmp_res) > len(curr_res) and tmp_res.rfind('.')!=-1: # we suppose sentence ended if it ended with '.' now\n",
    "            curr_res = tmp_res\n",
    "    sent_similarity = util.pytorch_cos_sim(embedding_input, \n",
    "                            model.encode(curr_res, convert_to_tensor=True)\n",
    "                            ).item()\n",
    "    if sent_similarity < 0.65: # then regenerate:\n",
    "        continue\n",
    "    # print(sent_similarity)\n",
    "    predicted_sentences.append(curr_res)\n",
    "    \n",
    "    curr_res = input_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the latest tech news about the world's best (and sometimes worst) hardware, apps, and much more.\""
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"publishes latest tech news covering the world's best ( and possibly worst ) hardware, apps, and much more.\",\n",
       " \"the latest tech blogs about the world's best ( and sometimes worst ) hardware, software, and possibly more.\",\n",
       " \"publishes latest technology news covering the world's fastest ( and sometimes worst ) hardware, apps, and even more.\",\n",
       " \"wired wired tech news covers the world's fastest ( and sometimes worst ) hardware, apps, and even more.\",\n",
       " \"the latest tech guide covers the world's best ( and sometimes worst ) websites, apps, and many more.\",\n",
       " \"its official blog talks about computing world' s best (and sometimes worst) hardware acceleration software...and about the new (but perhaps not so new!) Apple software.\",\n",
       " \"the latest latest article about the world's best ( and sometimes worst ) hardware security apps, reveals much more.\",\n",
       " \"the latest tech news about the world's best ( and sometimes worst ) hardware security apps, is much more.\",\n",
       " \"the latest tech news about the world's best ( and possibly worst ) websites, apps, and much more.\",\n",
       " \"• latest tech blogs about the world's best ( and sometimes worst ) hardware, apps, and many more.\"]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
